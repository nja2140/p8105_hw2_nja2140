---
title: "p8105_hw2_nja2140"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(readxl)
library(tidyverse)
```

Problem 1: Read and Clean the Mr. Trash Wheel dataset.
  -Specify the sheet in the Excel file and to omit non-data entries (rows with notes /     figures; columns containing notes) using arguments in read_excel
  -Use reasonable variable names
  -Omit rows that do not include dumpster-specific data
  -Round the number of sports balls to the nearest integer and converts the result to an    integer variable (using as.integer)
  
```{r}
trash_data = 
  read_excel("./Data/Trash_Wheel.xlsx", sheet = 1) %>%
  janitor::clean_names() %>%
  drop_na(dumpster) %>%
  select(-15,-16,-17) %>%
  mutate(sports_balls = as.integer (sports_balls))
trash_data
```
Read and clean precipitation data for 2017. Omit rows without precipitation data and add a variable year.

```{r}
trash17_data=
  read_excel("./Data/Trash_Wheel.xlsx", sheet = 6, skip = 1) %>%
  janitor::clean_names() %>%
  drop_na() %>%
  mutate(year = 2017)
```

Read and clean precipitation data for 2018. Omit rows without precipitation data and add a variable year.

```{r}
trash18_data=
  read_excel("./Data/Trash_Wheel.xlsx", sheet = 5, skip = 1) %>%
  janitor::clean_names() %>%
  drop_na() %>%
  mutate(year = 2018)
trash18_data
```

Combine precipitation datasets and convert month to a character variable (the variable month.name is built into R and should be useful

```{r}
precip_data=
  full_join(trash17_data, trash18_data) %>%
  mutate(month = month.abb[month]) 
precip_data
```
Write a paragraph about these data; you are encouraged to use inline R. Be sure to note the number of observations in both resulting datasets, and give examples of key variables. For available data, what was the total precipitation in 2018? What was the median number of sports balls in a dumpster in 2017?

The size of the dataset `trash_data` is `r nrow(trash_data)` obeervtaions and `r ncol(trash_data)` variables. The size of the dataset `precip_data` is `r nrow(precip_data)` observations and `r ncol(precip_data)` variables. Key variables include the type of trash picked up and when. The total precipitation for 2018 is `r sum(pull(trash18_data, total))`. The median number of sports balls in a dumpster in 2017 is `r median(pull(filter(trash_data, year == 2017),sports_balls))`.

Problem 2: Clean the pols-month dataset. Use separate() to break up the variable mon into integer variables year, month, and day; replace month number with month name; create a president variable taking values gop and dem, and remove prez_dem and prez_gop; and remove the day variable

```{r}
pol_data = 
  read_csv("./Data/pols-month.csv") %>%
  janitor::clean_names() %>%
  separate(mon, c("year", "month", "day")) %>%
  mutate(
    year = as.numeric(year),
    month = as.numeric(month),
    month = month.name[month]
    ) %>%
  mutate(president = ifelse(prez_gop ==1, "gop", "dem")) %>%
  select(-prez_gop, -prez_dem, -day)
pol_data
```
Second, clean the data in snp.csv using a similar process to the above. For consistency across datasets, arrange according to year and month, and organize so that year and month are the leading columns.

```{r}
snp_data =
  read_csv("./Data/snp.csv") %>%
  janitor::clean_names() %>%
  separate(date, c("month", "day", "year")) %>%
  mutate(year = as.numeric(year),
    month = as.numeric(month),
    month = month.name[month]
    ) %>%
  select(year, month, -day, close) %>%
  arrange (year, month)
snp_data
```
Tidy the unemployment data so that it can be merged with the previous datasets. This process will involve switching from “wide” to “long” format; ensuring that key variables have the same name; and ensuring that key variables take the same values.

```{r}
une_data = 
  read_csv("./Data/unemployment.csv") %>%
  janitor::clean_names() %>%
  pivot_longer(
    jan:dec,
    names_to = "month",
    values_to = "rate"
  )
une_data
```
Join the datasets by merging snp into pols, and merging unemployment into the result
```{r}
snppols_data=
  left_join(pol_data, snp_data)
snppols_data
total_data=
  left_join(snppols_data, une_data)
total_data
```
Write a short paragraph about these datasets. 

The size of the dataset `pol_data` is `r nrow(pol_data)` obeervtaions and `r ncol(pol_data)` variables. The size of the dataset `snp_data` is `r nrow(snp_data)` observations and `r ncol(snp_data)` variables. The size of the dataset `une_data` is `r nrow(une_data)` observations and `r ncol(une_data)` variables.The size of the dataset `total_data` is `r nrow(total_data)` observations and `r ncol(total_data)` variables. The resulting data set has data ranging from years 1947-2015. Key variables include the presidential and senators candidates party and unemployment rates.

Problem 3: Load and tidy the data. Note that, although these data may seem fairly well formatted initially, the names of a categorical predictor and the case structure of string variables changed over time; you’ll need to address this in your data cleaning. Also, some rows seem duplicated, and these will need to be removed (hint: google something like “dplyr remove duplicate rows” to get started)

```{r}
baby_data=
  read_csv("./Data/Popular_Baby_Names.csv") %>%
  janitor::clean_names() %>%
  distinct() %>%
  mutate(ethnicity = recode(ethnicity, "ASIAN AND PACI" = "ASIAN AND PACIFIC ISLANDER", "BLACK NON HISP" = "BLACK NON HISPANIC", "WHITE NON HISP" = "WHITE NON HISPANIC"), ethnicity = str_to_lower(ethnicity), gender = str_to_lower(gender), childs_first_name = str_to_lower(childs_first_name)) 
baby_data
view(baby_data)
```

